{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4aed35be",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# Topic Mining 1\n",
    "**Note**: \n",
    "This part of codes count directors, writers, casts names in each movies' posts.\n",
    "\n",
    "**Data Required**:\n",
    "imdb_scraped.csv, fbposts.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "0e661a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import gensim\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "66e5038f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the function of text cleaning\n",
    "def remove_special_characters(text,remove_digits=False):\n",
    "    pattern=r'[^a-zA-Z0-9\\s]' if not remove_digits else r'[^a-zA-Z\\s]'\n",
    "    text=re.sub(pattern,'',text)\n",
    "    return text\n",
    "\n",
    "def normalize(articles):\n",
    "    n_articles=[]\n",
    "    for article in articles:\n",
    "        article=remove_special_characters(article,True)\n",
    "        tokens = [token.strip() for token in nltk.tokenize.RegexpTokenizer(r'\\w+').tokenize(article)]\n",
    "        # word length>2\n",
    "        tokens = [token for token in tokens if len(token) > 2]\n",
    "        tokens = list(filter(None, tokens))\n",
    "        # if tokens:\n",
    "        n_articles.append(tokens)\n",
    "    return n_articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "db4e3361",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data scraped from imdb using automated crawler\n",
    "data1 = pd.read_csv('imdb_scraped.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "e247c309",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = pd.read_csv('fbposts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "9640f08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# group each movies' posts into one, and use this as unit of analysis\n",
    "data2 = data2.groupby(['imdb_id'])['message_and_description'].apply(lambda x: \"%s\" % ' '.join(x)).to_frame('posts').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "32668c92",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# filter out movies in imdb_scraped that do not have posts\n",
    "data1 = data1.loc[data1['imdb_id'].isin(data2['imdb_id'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "c276679d",
   "metadata": {},
   "outputs": [],
   "source": [
    "director = list(data1.director)\n",
    "writer = list(data1.writer)\n",
    "star = list(data1.star)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "884fe82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "posts = data2.posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "aab781df",
   "metadata": {},
   "outputs": [],
   "source": [
    "posts = normalize(posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "a763c2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use bigram to identify names\n",
    "def preprocess1(content):\n",
    "    bigram = gensim.models.Phrases(content, min_count=5, threshold=10,\n",
    "                                   delimiter='_') \n",
    "    bigram_model = gensim.models.phrases.Phraser(bigram)\n",
    "    doc_bigrams = [bigram_model[doc] for doc in content]\n",
    "    return doc_bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "99a8fd46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate two names\n",
    "def insertspace(columnname):\n",
    "    columnname = [str(x) for x in columnname]\n",
    "    columnname = [re.sub(r\"(\\w|\\))([A-Z,Ã‰])\", r\"\\1_\\2\", name) for name in columnname]\n",
    "    return columnname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "cba31c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert names into lists\n",
    "def preprocess2(columnname):\n",
    "    cn1 = insertspace(columnname)\n",
    "    d1 = [re.sub('Mc_','Mc',word) for word in cn1]\n",
    "    d1 = [re.sub('Mac_','Mac',word) for word in d1]\n",
    "    d1 = [re.sub('R_','R',word) for word in d1]\n",
    "    d1 = [re.sub('\\(.*?\\)','',word) for word in d1]\n",
    "    d2 = []\n",
    "    for name in d1:\n",
    "        name1 = name.split('_')\n",
    "        d2.append(name1)\n",
    "    d4 = []\n",
    "    for rows in d2:\n",
    "        d3 = []\n",
    "        for name in rows:\n",
    "            name1 = re.sub(' ','_',name)\n",
    "            d3.append(name1)\n",
    "        d4.append(d3)\n",
    "    return d4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "5c74bde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "director = preprocess2(director)\n",
    "writer = preprocess2(writer)\n",
    "star = preprocess2(star)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "a00075ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "posts = preprocess1(posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "d60c64f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_d = []\n",
    "counts_w = []\n",
    "counts_s = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "5005234a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count how many times directors names appear in posts\n",
    "for doc in posts:\n",
    "    count = 0\n",
    "    index = posts.index(doc)\n",
    "    for name in director[index]:\n",
    "        count += doc.count(name)\n",
    "    counts_d.append(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "c68b40a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count how many times writers names appear in posts\n",
    "for doc in posts:\n",
    "    count = 0\n",
    "    index = posts.index(doc)\n",
    "    for name in writer[index]:\n",
    "        count += doc.count(name)\n",
    "    counts_w.append(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "baa4da55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count how many times stars names appear in posts\n",
    "for doc in posts:\n",
    "    count = 0\n",
    "    index = posts.index(doc)\n",
    "    for name in star[index]:\n",
    "        count += doc.count(name)\n",
    "    counts_s.append(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "fd25d862",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2['dircount'] = counts_d\n",
    "data2['wricount'] = counts_w\n",
    "data2['strcount'] = counts_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "41a18b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.to_csv('count3.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
